---
title: "parsnip API"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{univariate-time-series}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(torch)
library(torchts)
library(rsample)
library(dplyr, warn.conflicts = FALSE)
library(ggplot2)
library(parsnip)
library(timetk)
```

## Preparing dataset

`parsnip` API provides quick and convenient way to train time series models based on `torch` library.

First, let's prepare input data set using excelent `timetk` library. `weather_pl` dataset from `torchts` package contains 19-year history of weather data from two Polish "poles of extreme temperature", i.e. Suwałki and Tarnów. In this excercise, we'll use a slice of data registered in the "pole of warmth", i.e in the city of [Tarnów](https://en.wikipedia.org/wiki/Tarn%C3%B3w).

```{r preparing.data.1}
tarnow_temp <- 
  weather_pl %>% 
  filter(station == "TRN") %>% 
  select(date, tmax_daily, tmin_daily, press_mean_daily)

tk_summary_diagnostics(tarnow_temp, date)
```

As we can see, this is a time series between 1th of Janury 2001 till the end of 2020 - twenty years.
In the next step, we'll split our data into two training and testing datasets using a handy `time_series_split` function.

```{r preparing.data.2}
# Splitting on training and test
data_split <- 
  time_series_split(
    tarnow_temp, date, 
    initial = "18 years",
    assess  = "2 years", 
    lag     = 20
  )

# Training dataset
tk_summary_diagnostics(training(data_split), date)[, 1:3]

# Testing dataset
tk_summary_diagnostics(testing(data_split), date)[, 1:3]
```
## Univariate time series

```{r univariate.ts}
TIMESTEPS <- 20
HORIZON   <- 1

# Training 
rnn_model <- 
  rnn(
    timesteps    = TIMESTEPS,
    horizon      = HORIZON,
    epochs       = 3,
    hidden_units = 20,
    batch_size   = 32,
    scale        = TRUE 
  ) %>% 
  fit(tmax_daily ~ date, 
      data = training(data_split))
```

We want to generate forecast for a full year. To do so, we'll remove the outcome column values
we'd like to forecast. Bear in mind that input data differs from the inputs for classical tabular-data algorithms.
In this specific case, we have to keep some "history" (in this case: `r TIMESTEPS` steps, i.e: `r TIMESTEPS` days).

```{r model.forecast.1}
# Clear outcome variable
cleared_new_data <- 
  testing(data_split) %>% 
  clear_outcome(date, tmax_daily, 20)

# Forecast
fcast <-
  rnn_model %>%
  predict(new_data = testing(data_split))

fcast_vs_true <- 
  bind_cols(testing(data_split), c(rep(NA, 20), fcast$.pred_V1))
```

## Multivariate time series

```{r multivariate.ts}
TIMESTEPS <- 20
HORIZON   <- 1
dev <- FALSE

# Training 
rnn_model <- 
  rnn(
    timesteps    = TIMESTEPS,
    horizon      = HORIZON,
    epochs       = 2,
    hidden_units = 5,
    batch_size   = 32,
    scale        = TRUE 
  ) %>% 
  fit(tmax_daily ~ press_mean_daily + tmax_daily + index(date), 
      data = training(data_split))
```



## Multivariate time series with multiple outcomes


```{r multivariate.ts.with.multioutput}
TIMESTEPS <- 20
HORIZON   <- 1
dev <- FALSE

# Training 
rnn_model <- 
  rnn(
    timesteps    = TIMESTEPS,
    horizon      = HORIZON,
    epochs       = 2,
    hidden_units = 5,
    batch_size   = 32,
    scale        = TRUE 
  ) %>% 
  fit(tmin_daily + tmax_daily ~ tmin_daily + tmax_daily + index(date), 
      data = training(data_split))
```


```{r multi.2}
# Clear outcome variable
cleared_new_data <- 
  testing(data_split) %>% 
  clear_outcome(date, c(tmax_daily, tmin_daily), 20)

# debugonce(torchts:::predict.torchts_rnn)

dev <- TRUE

rnn_model$preproc$y_var

# Forecast
fcast <-
  rnn_model %>%
  predict(new_data = cleared_new_data)
```


