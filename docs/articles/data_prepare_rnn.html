<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Preparing data for RNN models • torchts</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Preparing data for RNN models" />
<meta property="og:description" content="torchts" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">torchts</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/data_prepare_rnn.html">Preparing data for RNN models</a>
    </li>
    <li>
      <a href="../articles/missing_data.html">Handling missing data</a>
    </li>
    <li>
      <a href="../articles/prepare_tensor.html">Prepare tensor</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<script src="data_prepare_rnn_files/accessible-code-block-0.0.1/empty-anchor.js"></script>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Preparing data for RNN models</h1>
            
      
      
      <div class="hidden name"><code>data_prepare_rnn.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw">library</span>(magrittr)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw">library</span>(dplyr)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">#&gt; </span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co">#&gt; Dołączanie pakietu: &#39;dplyr&#39;</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co">#&gt; Następujące obiekty zostały zakryte z &#39;package:stats&#39;:</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">#&gt; </span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">#&gt;     filter, lag</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">#&gt; Następujące obiekty zostały zakryte z &#39;package:base&#39;:</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="co">#&gt; </span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="co">#&gt;     intersect, setdiff, setequal, union</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="kw">library</span>(torch)</span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="kw">library</span>(torchts)</span></code></pre></div>
<div id="downloading-m5-challenge-data-set" class="section level2">
<h2>Downloading M5 challenge data set</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Downloading Walmart data</span></span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="co"># Walmart data</span></span></code></pre></div>
<p>The M5 challenge data set is quite large, so it will be good to reduce the input data frame.</p>
</div>
<div id="data-wrangling" class="section level2">
<h2>Data Wrangling</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>walmart_foods_ca1_prepared &lt;-</span>
<span id="cb3-2"><a href="#cb3-2"></a><span class="st">  </span>fst<span class="op">::</span><span class="kw">read_fst</span>(<span class="st">&quot;../data/walmart/walmart_foods_ca1_prepared.fst&quot;</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a>experiment_data &lt;-</span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="st">  </span>walmart_foods_ca1_prepared <span class="op">%&gt;%</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="st">  </span><span class="kw">filter</span>(dept_id <span class="op">==</span><span class="st"> &quot;FOODS_1&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>snap_TX, <span class="op">-</span>snap_WI) <span class="op">%&gt;%</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="st">  </span><span class="kw">select</span>(item_id, d, wm_yr_wk, id, dept_id, value,</span>
<span id="cb3-9"><a href="#cb3-9"></a>         date, wday, month, year, event_name_<span class="dv">1</span>,</span>
<span id="cb3-10"><a href="#cb3-10"></a>         event_type_<span class="dv">1</span>, event_name_<span class="dv">2</span>, event_type_<span class="dv">2</span>, snap_CA,</span>
<span id="cb3-11"><a href="#cb3-11"></a>         sell_price)</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a>experiment_data &lt;-</span>
<span id="cb3-14"><a href="#cb3-14"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">date =</span> lubridate<span class="op">::</span><span class="kw">as_date</span>(date)) <span class="op">%&gt;%</span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="kw">across</span>(<span class="kw">where</span>(is.factor), as.character))</span>
<span id="cb3-17"><a href="#cb3-17"></a></span>
<span id="cb3-18"><a href="#cb3-18"></a>experiment_data &lt;-</span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span></span>
<span id="cb3-20"><a href="#cb3-20"></a><span class="st">  </span><span class="kw">select</span>(item_id, date,value, wday,</span>
<span id="cb3-21"><a href="#cb3-21"></a>         month, year, snap_CA, sell_price) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb3-22"><a href="#cb3-22"></a><span class="st">    </span><span class="kw">arrange</span>(item_id, date)</span></code></pre></div>
<p>We assume that we want to create a <strong>three-dimensional tensor</strong>, the each dimension of presents:</p>
<ul>
<li><strong>item</strong></li>
<li><strong>time steps</strong></li>
<li><strong>features</strong></li>
</ul>
<p>This assumption makes us to keep the data “complete”, i.e. every single item time series has to have the same <strong>length</strong>. The first dimension is “free”, and the completeness of the last dimension is guaranteed by the data.frame structure itself (each row has the same number of columns).</p>
<p>For simplicity’s sake, we can just select a subset of items with the same series length as well as the first and last date. In such case, we’ll be sure that our data are properly aligned in the tensor. Later, in a separate vignette, we’ll dive into a set of methods, how to handle missing/non-aligned multiple time series when training a deep learning model.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>data_summary &lt;-<span class="st"> </span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-3"><a href="#cb4-3"></a><span class="st">    </span><span class="kw">group_by</span>(item_id) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="st">    </span><span class="kw">summarise</span>(</span>
<span id="cb4-5"><a href="#cb4-5"></a>      <span class="dt">len =</span> <span class="kw">n</span>(),</span>
<span id="cb4-6"><a href="#cb4-6"></a>      <span class="dt">first_date =</span> <span class="kw">min</span>(date),</span>
<span id="cb4-7"><a href="#cb4-7"></a>      <span class="dt">last_date  =</span> <span class="kw">max</span>(date)</span>
<span id="cb4-8"><a href="#cb4-8"></a>    ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-9"><a href="#cb4-9"></a><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-10"><a href="#cb4-10"></a><span class="st">    </span><span class="kw">group_by</span>(len, first_date, last_date) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-11"><a href="#cb4-11"></a><span class="st">    </span><span class="kw">summarise</span>(</span>
<span id="cb4-12"><a href="#cb4-12"></a>      <span class="dt">n =</span> <span class="kw">n</span>(),</span>
<span id="cb4-13"><a href="#cb4-13"></a>      <span class="dt">item_id =</span> <span class="kw">list</span>(item_id)</span>
<span id="cb4-14"><a href="#cb4-14"></a>    ) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb4-15"><a href="#cb4-15"></a><span class="st">    </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</span>
<span id="cb4-16"><a href="#cb4-16"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span>
<span id="cb4-17"><a href="#cb4-17"></a><span class="co">#&gt; `summarise()` regrouping output by &#39;len&#39;, &#39;first_date&#39; (override with `.groups` argument)</span></span>
<span id="cb4-18"><a href="#cb4-18"></a></span>
<span id="cb4-19"><a href="#cb4-19"></a><span class="kw">print</span>(<span class="kw">head</span>(data_summary))</span>
<span id="cb4-20"><a href="#cb4-20"></a><span class="co">#&gt; # A tibble: 6 x 5</span></span>
<span id="cb4-21"><a href="#cb4-21"></a><span class="co">#&gt; # Groups:   len, first_date [6]</span></span>
<span id="cb4-22"><a href="#cb4-22"></a><span class="co">#&gt;     len first_date last_date      n item_id    </span></span>
<span id="cb4-23"><a href="#cb4-23"></a><span class="co">#&gt;   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;int&gt; &lt;list&gt;     </span></span>
<span id="cb4-24"><a href="#cb4-24"></a><span class="co">#&gt; 1  1913 2011-01-29 2016-04-24   101 &lt;chr [101]&gt;</span></span>
<span id="cb4-25"><a href="#cb4-25"></a><span class="co">#&gt; 2  1031 2013-06-29 2016-04-24     9 &lt;chr [9]&gt;  </span></span>
<span id="cb4-26"><a href="#cb4-26"></a><span class="co">#&gt; 3  1731 2011-07-30 2016-04-24     9 &lt;chr [9]&gt;  </span></span>
<span id="cb4-27"><a href="#cb4-27"></a><span class="co">#&gt; 4  1514 2012-03-03 2016-04-24     8 &lt;chr [8]&gt;  </span></span>
<span id="cb4-28"><a href="#cb4-28"></a><span class="co">#&gt; 5  1906 2011-02-05 2016-04-24     6 &lt;chr [6]&gt;  </span></span>
<span id="cb4-29"><a href="#cb4-29"></a><span class="co">#&gt; 6  1164 2013-02-16 2016-04-24     5 &lt;chr [5]&gt;</span></span></code></pre></div>
<p>We choose a subset consisting of 101 products - each product has:</p>
<ul>
<li>lenght: 1913 days</li>
<li>first_date: 2011-01-29</li>
<li>last_date: 2016-04-24</li>
</ul>
<p>If we check the tme difference between these two dates</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="kw">as.Date</span>(<span class="st">&#39;2016-04-24&#39;</span>) <span class="op">-</span><span class="st"> </span><span class="kw">as.Date</span>(<span class="st">&#39;2011-01-29&#39;</span>)</span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co">#&gt; Time difference of 1912 days</span></span></code></pre></div>
<p>we’ll can see that there are no gaps in the subset we’ve just selected, so we have not to do any additional filtering or aligning.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>selected_items &lt;-<span class="st"> </span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="st">  </span>data_summary[<span class="dv">1</span>, ] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="st">  </span><span class="kw">pull</span>(item_id) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="st">  </span><span class="kw">unlist</span>()</span>
<span id="cb6-5"><a href="#cb6-5"></a></span>
<span id="cb6-6"><a href="#cb6-6"></a>experiment_data &lt;-<span class="st"> </span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="st">  </span><span class="kw">filter</span>(item_id <span class="op">%in%</span><span class="st"> </span>selected_items)</span>
<span id="cb6-9"><a href="#cb6-9"></a></span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="kw">print</span>(<span class="kw">nrow</span>(experiment_data))</span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="co">#&gt; [1] 193213</span></span></code></pre></div>
<p>Let’s take a look on the data we’ve already prepared.</p>
</div>
<div id="transorming-to-tensor" class="section level2">
<h2>Transorming to tensor</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw">head</span>(experiment_data)</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="co">#&gt;       item_id       date value wday month year snap_CA sell_price</span></span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="co">#&gt; 1 FOODS_1_001 2011-01-29     3    1     1 2011       0          2</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">#&gt; 2 FOODS_1_001 2011-01-30     0    2     1 2011       0          2</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="co">#&gt; 3 FOODS_1_001 2011-01-31     0    3     1 2011       0          2</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">#&gt; 4 FOODS_1_001 2011-02-01     1    4     2 2011       1          2</span></span>
<span id="cb7-7"><a href="#cb7-7"></a><span class="co">#&gt; 5 FOODS_1_001 2011-02-02     4    5     2 2011       1          2</span></span>
<span id="cb7-8"><a href="#cb7-8"></a><span class="co">#&gt; 6 FOODS_1_001 2011-02-03     2    6     2 2011       1          2</span></span></code></pre></div>
<p>The first column, <code>item_id</code>, describes the item we already the item and the second one (<code>date</code>) - a current time step. These two columns will be used to create a data “fold”, i.e. form a 3D tensor. As we mentioned above, the completness of the time moments is crucial to obtain a proper result from this transformation.</p>
<p>If it comes, to the rest of columns:</p>
<ul>
<li><code>value</code> is a target we want to predict</li>
<li><code>wday</code> is a categorical variable</li>
<li><code>month</code> is a categorical variable</li>
<li><code>year</code> <em>can</em> be treated as categorical, but in this case we may remove this variable and introduce a counter instead</li>
<li><code>snap_CA</code> is a categorical variable</li>
<li><code>sell_price</code> is a real-valued variable</li>
</ul>
<p>Summarizing, we have three categorical variables, which should be represented in some way. The most efficient manner to represent categorical variables in neural network is <strong>embedding</strong> layer.<br />
In fact, it works similar to a <strong>linear</strong> (<strong>dense</strong>) layer. The difference is that instead of performing resource-consuming dot product between weight matrix and the input one-hot encoded sparse matrix, we just use an index to select “right” row from the weight matrix.</p>
<p>Because of this index-based nature of embedding, we need to transform all the categorical features to 1-n to range.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>experiment_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="st">  </span><span class="kw">select</span>(wday, month, snap_CA) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb8-3"><a href="#cb8-3"></a><span class="st">  </span><span class="kw">sapply</span>(unique)</span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="co">#&gt; $wday</span></span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="co">#&gt; [1] 1 2 3 4 5 6 7</span></span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="co">#&gt; </span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="co">#&gt; $month</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="co">#&gt;  [1]  1  2  3  4  5  6  7  8  9 10 11 12</span></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co">#&gt; </span></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="co">#&gt; $snap_CA</span></span>
<span id="cb8-11"><a href="#cb8-11"></a><span class="co">#&gt; [1] 0 1</span></span></code></pre></div>
<p>In this case the only variable we need to recode is snap_Ca.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>experiment_data &lt;-<span class="st"> </span></span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">snap_CA =</span> <span class="kw">ifelse</span>(snap_CA <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>d_size &lt;-</span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="st">  </span><span class="kw">select</span>(</span>
<span id="cb10-4"><a href="#cb10-4"></a>    wday, month,</span>
<span id="cb10-5"><a href="#cb10-5"></a>    snap_CA</span>
<span id="cb10-6"><a href="#cb10-6"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="st">  </span><span class="kw">dict_size</span>()</span></code></pre></div>
<p>Let’s transform tabular data into tensor. A good way to do it is to use a convenient <code>as_tensor</code> function. The first argument of the function (described as <code>.data</code>) is a <code>data.frame</code> object, which we want to transform into a <code>torch_tensor</code>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>X_tensor_cat &lt;-</span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="st">  </span><span class="kw">select</span>(</span>
<span id="cb11-4"><a href="#cb11-4"></a>    item_id, date, wday, month,</span>
<span id="cb11-5"><a href="#cb11-5"></a>    snap_CA</span>
<span id="cb11-6"><a href="#cb11-6"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb11-7"><a href="#cb11-7"></a><span class="st">  </span><span class="kw">as_tensor</span>(item_id, date, <span class="dt">dtype =</span> <span class="kw">torch_long</span>())</span>
<span id="cb11-8"><a href="#cb11-8"></a></span>
<span id="cb11-9"><a href="#cb11-9"></a>X_tensor_rest &lt;-<span class="st"> </span></span>
<span id="cb11-10"><a href="#cb11-10"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span></span>
<span id="cb11-11"><a href="#cb11-11"></a><span class="st">  </span><span class="kw">select</span>(</span>
<span id="cb11-12"><a href="#cb11-12"></a>    item_id, date, wday, month,</span>
<span id="cb11-13"><a href="#cb11-13"></a>    snap_CA</span>
<span id="cb11-14"><a href="#cb11-14"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb11-15"><a href="#cb11-15"></a><span class="st">  </span><span class="kw">as_tensor</span>(item_id, date, <span class="dt">dtype =</span> <span class="kw">torch_long</span>())</span>
<span id="cb11-16"><a href="#cb11-16"></a></span>
<span id="cb11-17"><a href="#cb11-17"></a><span class="kw">print</span>(<span class="kw">class</span>(X_tensor_cat))</span>
<span id="cb11-18"><a href="#cb11-18"></a><span class="co">#&gt; [1] &quot;torch_tensor&quot; &quot;R7&quot;</span></span>
<span id="cb11-19"><a href="#cb11-19"></a><span class="kw">print</span>(X_tensor_cat<span class="op">$</span>shape)</span>
<span id="cb11-20"><a href="#cb11-20"></a><span class="co">#&gt; [1]  101 1913    3</span></span>
<span id="cb11-21"><a href="#cb11-21"></a></span>
<span id="cb11-22"><a href="#cb11-22"></a>y_tensor &lt;-</span>
<span id="cb11-23"><a href="#cb11-23"></a><span class="st">  </span>experiment_data <span class="op">%&gt;%</span></span>
<span id="cb11-24"><a href="#cb11-24"></a><span class="st">  </span><span class="kw">select</span>(item_id, date, value) <span class="op">%&gt;%</span></span>
<span id="cb11-25"><a href="#cb11-25"></a><span class="st">  </span><span class="kw">as_tensor</span>(item_id, date, <span class="dt">dtype =</span> <span class="kw">torch_float</span>())</span></code></pre></div>
<div id="embedding-for-categorical-variables" class="section level3">
<h3>Embedding for categorical variables</h3>
<p>First, let’s create <strong>a multiple embedding module</strong>. A causal <strong>embedding module</strong> is a simple, but memory efficient operation, which allows us to transform a sequence of categorical features into sequence of embedding vectors.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a></span>
<span id="cb12-2"><a href="#cb12-2"></a>embedding &lt;-<span class="st"> </span></span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="st">  </span><span class="kw">nn_multi_embedding</span>(</span>
<span id="cb12-4"><a href="#cb12-4"></a>    <span class="dt">num_embeddings =</span> d_size,</span>
<span id="cb12-5"><a href="#cb12-5"></a>    <span class="dt">embedding_dim  =</span> <span class="kw">rep</span>(<span class="dv">3</span>, <span class="kw">length</span>(d_size))</span>
<span id="cb12-6"><a href="#cb12-6"></a>  )</span>
<span id="cb12-7"><a href="#cb12-7"></a></span>
<span id="cb12-8"><a href="#cb12-8"></a>X_tensor_cat_processed &lt;-<span class="st">  </span><span class="kw">embedding</span>(X_tensor_cat)</span></code></pre></div>
</div>
<div id="feature-concatenation" class="section level3">
<h3>Feature concatenation</h3>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>X_transformed &lt;-<span class="st"> </span><span class="kw">torch_cat</span>(</span>
<span id="cb13-2"><a href="#cb13-2"></a>  <span class="kw">list</span>(X_tensor_rest, X_tensor_cat_processed), <span class="dt">dim =</span> <span class="dv">-1</span></span>
<span id="cb13-3"><a href="#cb13-3"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1"></a>recurrent_layer &lt;-<span class="st"> </span><span class="kw">nn_gru</span>(<span class="dv">12</span>, <span class="dv">48</span>)</span>
<span id="cb14-2"><a href="#cb14-2"></a>out &lt;-<span class="st"> </span><span class="kw">recurrent_layer</span>(X_transformed)</span>
<span id="cb14-3"><a href="#cb14-3"></a>out </span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co">#&gt; [[1]]</span></span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb14-6"><a href="#cb14-6"></a><span class="co">#&gt; (1,.,.) = </span></span>
<span id="cb14-7"><a href="#cb14-7"></a><span class="co">#&gt;  Columns 1 to 9  0.0256 -0.1242 -0.3339  0.2648  0.1801 -0.0003  0.0200  0.2048  0.1610</span></span>
<span id="cb14-8"><a href="#cb14-8"></a><span class="co">#&gt;   0.2190  0.1767 -0.0427  0.2249 -0.0109  0.0300 -0.3506  0.1030  0.4780</span></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="co">#&gt;   0.0624  0.3046 -0.0830  0.4838  0.3099 -0.0072 -0.5351  0.0895  0.7435</span></span>
<span id="cb14-10"><a href="#cb14-10"></a><span class="co">#&gt;   0.3044 -0.1540 -0.1656  0.3277  0.3261 -0.1717 -0.6431  0.0734  0.7140</span></span>
<span id="cb14-11"><a href="#cb14-11"></a><span class="co">#&gt;  -0.2282  0.4962 -0.1163  0.4615  0.2969  0.0106 -0.2669  0.1105  0.4910</span></span>
<span id="cb14-12"><a href="#cb14-12"></a><span class="co">#&gt;  -0.0088 -0.0955 -0.1496  0.1435  0.4353 -0.0755 -0.3833  0.0882  0.2949</span></span>
<span id="cb14-13"><a href="#cb14-13"></a><span class="co">#&gt;  -0.0588  0.3647 -0.1485  0.3943  0.3587 -0.1550 -0.5765  0.0600  0.7071</span></span>
<span id="cb14-14"><a href="#cb14-14"></a><span class="co">#&gt;   0.0083 -0.0825 -0.3650  0.3829  0.2097  0.0424 -0.0243  0.1781  0.2513</span></span>
<span id="cb14-15"><a href="#cb14-15"></a><span class="co">#&gt;  -0.0477  0.1472 -0.1204  0.1500  0.2182 -0.0089 -0.2977  0.1193  0.2962</span></span>
<span id="cb14-16"><a href="#cb14-16"></a><span class="co">#&gt;  -0.0926  0.5672 -0.1561  0.3868  0.3252 -0.0656 -0.4747  0.0946  0.7089</span></span>
<span id="cb14-17"><a href="#cb14-17"></a><span class="co">#&gt;   0.2792 -0.1018 -0.1804  0.4180  0.3480 -0.1309 -0.6847  0.0726  0.7315</span></span>
<span id="cb14-18"><a href="#cb14-18"></a><span class="co">#&gt;  -0.1232  0.4412  0.2114  0.0650 -0.1030  0.0200 -0.0658  0.0188  0.2166</span></span>
<span id="cb14-19"><a href="#cb14-19"></a><span class="co">#&gt;   0.2431  0.0045  0.0138 -0.0793  0.0319 -0.0604 -0.2184  0.0234  0.2323</span></span>
<span id="cb14-20"><a href="#cb14-20"></a><span class="co">#&gt;  -0.0934  0.3986 -0.1739  0.4931  0.3823 -0.1185 -0.6243  0.0640  0.7342</span></span>
<span id="cb14-21"><a href="#cb14-21"></a><span class="co">#&gt;   0.5807 -0.5822 -0.1086  0.3422  0.2111 -0.0787 -0.5700  0.0906  0.7237</span></span>
<span id="cb14-22"><a href="#cb14-22"></a><span class="co">#&gt;  -0.0175  0.1051 -0.1800  0.2044  0.2996  0.0351 -0.2395  0.1524  0.2550</span></span>
<span id="cb14-23"><a href="#cb14-23"></a><span class="co">#&gt;  -0.1266  0.5856 -0.1963  0.5019  0.3491 -0.0369 -0.5302  0.0944  0.7346</span></span>
<span id="cb14-24"><a href="#cb14-24"></a><span class="co">#&gt;   0.4180 -0.0564 -0.1463  0.2573  0.1383 -0.1554 -0.5849  0.0679  0.7042</span></span>
<span id="cb14-25"><a href="#cb14-25"></a><span class="co">#&gt;  -0.2974  0.5159 -0.1540  0.3466  0.3412 -0.0098 -0.1074  0.1386  0.2436</span></span>
<span id="cb14-26"><a href="#cb14-26"></a><span class="co">#&gt;  -0.1912  0.5424  0.1985  0.4363 -0.1601  0.0503 -0.1227  0.0846  0.4408</span></span>
<span id="cb14-27"><a href="#cb14-27"></a><span class="co">#&gt;   0.2869  0.1815  0.0126  0.0813 -0.2576 -0.1329 -0.2434  0.0229  0.4081</span></span>
<span id="cb14-28"><a href="#cb14-28"></a><span class="co">#&gt;   0.0914  0.1742 -0.0746  0.4077  0.3616 -0.0055 -0.5311  0.0805  0.6841</span></span>
<span id="cb14-29"><a href="#cb14-29"></a><span class="co">#&gt;   0.3835 -0.3982 -0.0689  0.3768  0.5091 -0.0031 -0.6930  0.0568  0.7189</span></span>
<span id="cb14-30"><a href="#cb14-30"></a><span class="co">#&gt;  -0.1629  0.4735 -0.0550  0.3220  0.1416 -0.0853 -0.1645  0.0873  0.3772</span></span>
<span id="cb14-31"><a href="#cb14-31"></a><span class="co">#&gt;   0.2051 -0.3000 -0.2558  0.2576  0.1923 -0.0986 -0.2668  0.1426  0.4337</span></span>
<span id="cb14-32"><a href="#cb14-32"></a><span class="co">#&gt;   0.3556 -0.0544 -0.1835  0.3310  0.4079 -0.0245 -0.6626  0.0911  0.7348</span></span>
<span id="cb14-33"><a href="#cb14-33"></a><span class="co">#&gt;  -0.3388  0.6048 -0.1586  0.4193  0.3044 -0.0110 -0.1036  0.1512  0.3552</span></span>
<span id="cb14-34"><a href="#cb14-34"></a><span class="co">#&gt;  -0.0025  0.1896 -0.1003  0.2171  0.0017 -0.1304 -0.2551  0.0863  0.3099</span></span>
<span id="cb14-35"><a href="#cb14-35"></a><span class="co">#&gt;   0.0622  0.2122 -0.0990  0.5577  0.3896  0.0245 -0.5824  0.0830  0.7421</span></span>
<span id="cb14-36"><a href="#cb14-36"></a><span class="co">#&gt; ... [the output was truncated (use n=-1 to disable)]</span></span>
<span id="cb14-37"><a href="#cb14-37"></a><span class="co">#&gt; [ CPUFloatType{101,1913,48} ]</span></span>
<span id="cb14-38"><a href="#cb14-38"></a><span class="co">#&gt; </span></span>
<span id="cb14-39"><a href="#cb14-39"></a><span class="co">#&gt; [[2]]</span></span>
<span id="cb14-40"><a href="#cb14-40"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb14-41"><a href="#cb14-41"></a><span class="co">#&gt; (1,.,.) = </span></span>
<span id="cb14-42"><a href="#cb14-42"></a><span class="co">#&gt;  Columns 1 to 6  4.0838e-01  1.3168e-01 -1.0777e-02  3.3567e-01 -2.5530e-01 -8.0976e-02</span></span>
<span id="cb14-43"><a href="#cb14-43"></a><span class="co">#&gt;   2.2620e-01  4.4763e-02 -2.9537e-01  6.1124e-01  4.6667e-01 -1.4833e-01</span></span>
<span id="cb14-44"><a href="#cb14-44"></a><span class="co">#&gt;   4.3367e-01 -5.5614e-01 -5.0344e-01  4.5727e-01  6.4173e-01 -4.2731e-01</span></span>
<span id="cb14-45"><a href="#cb14-45"></a><span class="co">#&gt;  -1.0939e-01  4.4645e-01 -2.7277e-01  7.4079e-01  3.1256e-01 -2.3819e-02</span></span>
<span id="cb14-46"><a href="#cb14-46"></a><span class="co">#&gt;   1.1483e-01 -2.5080e-01 -3.5783e-01  5.7197e-01  3.9135e-01 -2.9434e-01</span></span>
<span id="cb14-47"><a href="#cb14-47"></a><span class="co">#&gt;   2.4611e-01 -3.5660e-01 -5.0878e-01  5.6174e-01  6.2437e-01 -3.6516e-01</span></span>
<span id="cb14-48"><a href="#cb14-48"></a><span class="co">#&gt;  -4.5337e-01  7.4649e-01 -2.7879e-01  8.4128e-01  5.0853e-01 -9.2493e-02</span></span>
<span id="cb14-49"><a href="#cb14-49"></a><span class="co">#&gt;   6.8292e-02 -2.1735e-02 -1.4677e-01  2.6798e-01  1.3760e-01 -2.5573e-01</span></span>
<span id="cb14-50"><a href="#cb14-50"></a><span class="co">#&gt;   3.4414e-02  4.1919e-01 -3.1142e-01  5.1675e-01  4.4977e-01 -3.5160e-01</span></span>
<span id="cb14-51"><a href="#cb14-51"></a><span class="co">#&gt;   4.0075e-01 -4.9315e-01 -4.7099e-01  7.0635e-01  6.5018e-01 -3.2765e-01</span></span>
<span id="cb14-52"><a href="#cb14-52"></a><span class="co">#&gt;  -1.0458e-02  3.3990e-01  2.4494e-01  9.2111e-02 -2.3370e-01  8.4954e-02</span></span>
<span id="cb14-53"><a href="#cb14-53"></a><span class="co">#&gt;   4.6392e-01  1.1097e-02  9.6361e-02  2.4419e-02 -3.1171e-01 -1.5066e-01</span></span>
<span id="cb14-54"><a href="#cb14-54"></a><span class="co">#&gt;   2.1638e-01 -2.7338e-01 -4.5483e-01  7.6923e-01  6.2794e-01 -1.7588e-01</span></span>
<span id="cb14-55"><a href="#cb14-55"></a><span class="co">#&gt;   1.9508e-01  3.2817e-02 -3.9555e-01  6.8258e-01  4.4370e-01 -2.6243e-01</span></span>
<span id="cb14-56"><a href="#cb14-56"></a><span class="co">#&gt;   1.5342e-01 -5.5041e-02 -2.4884e-01  4.1603e-01  3.0674e-01 -1.5230e-01</span></span>
<span id="cb14-57"><a href="#cb14-57"></a><span class="co">#&gt;  -4.8685e-02  4.6719e-01 -3.5912e-01  7.4614e-01  4.8801e-01 -2.9637e-01</span></span>
<span id="cb14-58"><a href="#cb14-58"></a><span class="co">#&gt;   5.7197e-01 -4.2901e-01 -4.2830e-01  3.7444e-01  4.6385e-01 -3.1468e-01</span></span>
<span id="cb14-59"><a href="#cb14-59"></a><span class="co">#&gt;  -2.7788e-01  4.4296e-01 -2.6352e-01  6.0448e-01  4.9824e-01 -1.5506e-01</span></span>
<span id="cb14-60"><a href="#cb14-60"></a><span class="co">#&gt;  -1.2227e-01  5.5199e-01  2.1682e-01  4.6208e-01 -1.0535e-01  6.3083e-02</span></span>
<span id="cb14-61"><a href="#cb14-61"></a><span class="co">#&gt;   4.5180e-01 -6.4957e-02  8.7279e-02 -1.5478e-01 -5.3849e-02 -1.2095e-01</span></span>
<span id="cb14-62"><a href="#cb14-62"></a><span class="co">#&gt;   3.2376e-01 -7.5764e-02 -3.1129e-01  6.2355e-01  3.8567e-01 -1.7510e-01</span></span>
<span id="cb14-63"><a href="#cb14-63"></a><span class="co">#&gt;   5.7610e-01 -5.9457e-01 -4.7360e-01  8.1711e-01  3.5003e-01 -2.2482e-01</span></span>
<span id="cb14-64"><a href="#cb14-64"></a><span class="co">#&gt;   1.0849e-01 -5.4690e-02 -2.9724e-01  4.0190e-01  4.2336e-01 -4.6243e-02</span></span>
<span id="cb14-65"><a href="#cb14-65"></a><span class="co">#&gt;  -3.1454e-01  5.3780e-01 -2.4394e-01  6.1204e-01  4.7582e-01 -3.4211e-01</span></span>
<span id="cb14-66"><a href="#cb14-66"></a><span class="co">#&gt;   4.8058e-01 -2.7408e-01 -4.8506e-01  6.5405e-01  2.7626e-01 -4.0614e-01</span></span>
<span id="cb14-67"><a href="#cb14-67"></a><span class="co">#&gt;  -4.2335e-01  6.4198e-01 -3.2067e-01  8.1720e-01  5.6074e-01 -1.2188e-02</span></span>
<span id="cb14-68"><a href="#cb14-68"></a><span class="co">#&gt;   7.5750e-02 -1.2973e-01 -1.2718e-01  1.7344e-01  3.2719e-01 -1.8064e-01</span></span>
<span id="cb14-69"><a href="#cb14-69"></a><span class="co">#&gt;   1.4093e-01  3.0654e-01 -3.4728e-01  5.1614e-01  3.6192e-01 -3.6665e-01</span></span>
<span id="cb14-70"><a href="#cb14-70"></a><span class="co">#&gt;   4.3581e-01 -4.7666e-01 -5.5448e-01  8.3171e-01  4.4247e-01 -3.4410e-01</span></span>
<span id="cb14-71"><a href="#cb14-71"></a><span class="co">#&gt; ... [the output was truncated (use n=-1 to disable)]</span></span>
<span id="cb14-72"><a href="#cb14-72"></a><span class="co">#&gt; [ CPUFloatType{1,1913,48} ]</span></span>
<span id="cb14-73"><a href="#cb14-73"></a></span>
<span id="cb14-74"><a href="#cb14-74"></a><span class="kw">nn_linear</span>(<span class="dv">48</span>, <span class="dv">1</span>)(out[[<span class="dv">1</span>]])</span>
<span id="cb14-75"><a href="#cb14-75"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb14-76"><a href="#cb14-76"></a><span class="co">#&gt; (1,.,.) = </span></span>
<span id="cb14-77"><a href="#cb14-77"></a><span class="co">#&gt;  -0.0628</span></span>
<span id="cb14-78"><a href="#cb14-78"></a><span class="co">#&gt;  -0.0625</span></span>
<span id="cb14-79"><a href="#cb14-79"></a><span class="co">#&gt;  -0.1326</span></span>
<span id="cb14-80"><a href="#cb14-80"></a><span class="co">#&gt;  -0.1778</span></span>
<span id="cb14-81"><a href="#cb14-81"></a><span class="co">#&gt;  -0.0353</span></span>
<span id="cb14-82"><a href="#cb14-82"></a><span class="co">#&gt;   0.0177</span></span>
<span id="cb14-83"><a href="#cb14-83"></a><span class="co">#&gt;  -0.1367</span></span>
<span id="cb14-84"><a href="#cb14-84"></a><span class="co">#&gt;  -0.1106</span></span>
<span id="cb14-85"><a href="#cb14-85"></a><span class="co">#&gt;   0.0591</span></span>
<span id="cb14-86"><a href="#cb14-86"></a><span class="co">#&gt;  -0.1394</span></span>
<span id="cb14-87"><a href="#cb14-87"></a><span class="co">#&gt;  -0.1862</span></span>
<span id="cb14-88"><a href="#cb14-88"></a><span class="co">#&gt;   0.2158</span></span>
<span id="cb14-89"><a href="#cb14-89"></a><span class="co">#&gt;   0.0237</span></span>
<span id="cb14-90"><a href="#cb14-90"></a><span class="co">#&gt;  -0.1479</span></span>
<span id="cb14-91"><a href="#cb14-91"></a><span class="co">#&gt;  -0.1715</span></span>
<span id="cb14-92"><a href="#cb14-92"></a><span class="co">#&gt;   0.0036</span></span>
<span id="cb14-93"><a href="#cb14-93"></a><span class="co">#&gt;  -0.1594</span></span>
<span id="cb14-94"><a href="#cb14-94"></a><span class="co">#&gt;  -0.2086</span></span>
<span id="cb14-95"><a href="#cb14-95"></a><span class="co">#&gt;   0.0273</span></span>
<span id="cb14-96"><a href="#cb14-96"></a><span class="co">#&gt;   0.1362</span></span>
<span id="cb14-97"><a href="#cb14-97"></a><span class="co">#&gt;  -0.0486</span></span>
<span id="cb14-98"><a href="#cb14-98"></a><span class="co">#&gt;  -0.1093</span></span>
<span id="cb14-99"><a href="#cb14-99"></a><span class="co">#&gt;  -0.1024</span></span>
<span id="cb14-100"><a href="#cb14-100"></a><span class="co">#&gt;  -0.0124</span></span>
<span id="cb14-101"><a href="#cb14-101"></a><span class="co">#&gt;  -0.0981</span></span>
<span id="cb14-102"><a href="#cb14-102"></a><span class="co">#&gt;  -0.2038</span></span>
<span id="cb14-103"><a href="#cb14-103"></a><span class="co">#&gt;   0.0189</span></span>
<span id="cb14-104"><a href="#cb14-104"></a><span class="co">#&gt;   0.0213</span></span>
<span id="cb14-105"><a href="#cb14-105"></a><span class="co">#&gt;  -0.1407</span></span>
<span id="cb14-106"><a href="#cb14-106"></a><span class="co">#&gt; ... [the output was truncated (use n=-1 to disable)]</span></span>
<span id="cb14-107"><a href="#cb14-107"></a><span class="co">#&gt; [ CPUFloatType{101,1913,1} ]</span></span>
<span id="cb14-108"><a href="#cb14-108"></a></span>
<span id="cb14-109"><a href="#cb14-109"></a></span>
<span id="cb14-110"><a href="#cb14-110"></a>simple_rnn &lt;-<span class="st"> </span><span class="kw">nn_module</span>(</span>
<span id="cb14-111"><a href="#cb14-111"></a>  <span class="st">&quot;nn_simple_rnn&quot;</span>,</span>
<span id="cb14-112"><a href="#cb14-112"></a>  <span class="dt">initialize =</span> <span class="cf">function</span>(num_embeddings, embedding_dim, rnn_input_size, output_size){</span>
<span id="cb14-113"><a href="#cb14-113"></a>    self<span class="op">$</span>embedding &lt;-<span class="st"> </span><span class="kw">nn_multi_embedding</span>(num_embeddings, embedding_dim)</span>
<span id="cb14-114"><a href="#cb14-114"></a>    self<span class="op">$</span>recurrent_layer &lt;-<span class="st"> </span><span class="kw">nn_gru</span>(rnn_input_size, output_size)</span>
<span id="cb14-115"><a href="#cb14-115"></a>    self<span class="op">$</span>linear &lt;-<span class="st"> </span><span class="kw">nn_linear</span>(output_size, <span class="dv">1</span>)</span>
<span id="cb14-116"><a href="#cb14-116"></a>  },</span>
<span id="cb14-117"><a href="#cb14-117"></a>  <span class="dt">forward =</span> <span class="cf">function</span>(input_cat, input_rest){</span>
<span id="cb14-118"><a href="#cb14-118"></a>    X_tensor_cat_processed &lt;-<span class="st"> </span>self<span class="op">$</span><span class="kw">embedding</span>(X_tensor_cat)</span>
<span id="cb14-119"><a href="#cb14-119"></a>    X_transformed &lt;-<span class="st"> </span><span class="kw">torch_cat</span>(</span>
<span id="cb14-120"><a href="#cb14-120"></a>        <span class="kw">list</span>(X_tensor_rest, X_tensor_cat_processed), <span class="dt">dim =</span> <span class="dv">-1</span></span>
<span id="cb14-121"><a href="#cb14-121"></a>    )</span>
<span id="cb14-122"><a href="#cb14-122"></a>    out &lt;-<span class="st"> </span><span class="kw">recurrent_layer</span>(X_transformed)</span>
<span id="cb14-123"><a href="#cb14-123"></a>    <span class="kw">nnf_relu</span>(self<span class="op">$</span><span class="kw">linear</span>(<span class="kw">nnf_relu</span>(out[[<span class="dv">1</span>]])))</span>
<span id="cb14-124"><a href="#cb14-124"></a>  }</span>
<span id="cb14-125"><a href="#cb14-125"></a>)</span>
<span id="cb14-126"><a href="#cb14-126"></a></span>
<span id="cb14-127"><a href="#cb14-127"></a>simple_rnn_instance &lt;-<span class="st"> </span><span class="kw">simple_rnn</span>(d_size, <span class="kw">rep</span>(<span class="dv">3</span>, <span class="kw">length</span>(d_size)), <span class="dv">12</span>, <span class="dv">48</span>)</span>
<span id="cb14-128"><a href="#cb14-128"></a><span class="kw">simple_rnn_instance</span>(X_tensor_cat, X_tensor_rest)</span>
<span id="cb14-129"><a href="#cb14-129"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb14-130"><a href="#cb14-130"></a><span class="co">#&gt; (1,.,.) = </span></span>
<span id="cb14-131"><a href="#cb14-131"></a><span class="co">#&gt;   0.0106</span></span>
<span id="cb14-132"><a href="#cb14-132"></a><span class="co">#&gt;   0.1610</span></span>
<span id="cb14-133"><a href="#cb14-133"></a><span class="co">#&gt;   0.1817</span></span>
<span id="cb14-134"><a href="#cb14-134"></a><span class="co">#&gt;   0.2635</span></span>
<span id="cb14-135"><a href="#cb14-135"></a><span class="co">#&gt;   0.0000</span></span>
<span id="cb14-136"><a href="#cb14-136"></a><span class="co">#&gt;   0.1427</span></span>
<span id="cb14-137"><a href="#cb14-137"></a><span class="co">#&gt;   0.2308</span></span>
<span id="cb14-138"><a href="#cb14-138"></a><span class="co">#&gt;   0.0098</span></span>
<span id="cb14-139"><a href="#cb14-139"></a><span class="co">#&gt;   0.0230</span></span>
<span id="cb14-140"><a href="#cb14-140"></a><span class="co">#&gt;   0.1691</span></span>
<span id="cb14-141"><a href="#cb14-141"></a><span class="co">#&gt;   0.2629</span></span>
<span id="cb14-142"><a href="#cb14-142"></a><span class="co">#&gt;   0.0000</span></span>
<span id="cb14-143"><a href="#cb14-143"></a><span class="co">#&gt;   0.1815</span></span>
<span id="cb14-144"><a href="#cb14-144"></a><span class="co">#&gt;   0.2100</span></span>
<span id="cb14-145"><a href="#cb14-145"></a><span class="co">#&gt;   0.2693</span></span>
<span id="cb14-146"><a href="#cb14-146"></a><span class="co">#&gt;   0.0000</span></span>
<span id="cb14-147"><a href="#cb14-147"></a><span class="co">#&gt;   0.1746</span></span>
<span id="cb14-148"><a href="#cb14-148"></a><span class="co">#&gt;   0.2337</span></span>
<span id="cb14-149"><a href="#cb14-149"></a><span class="co">#&gt;   0.0000</span></span>
<span id="cb14-150"><a href="#cb14-150"></a><span class="co">#&gt;   0.0000</span></span>
<span id="cb14-151"><a href="#cb14-151"></a><span class="co">#&gt;   0.1657</span></span>
<span id="cb14-152"><a href="#cb14-152"></a><span class="co">#&gt;   0.2211</span></span>
<span id="cb14-153"><a href="#cb14-153"></a><span class="co">#&gt;   0.2785</span></span>
<span id="cb14-154"><a href="#cb14-154"></a><span class="co">#&gt;   0.0260</span></span>
<span id="cb14-155"><a href="#cb14-155"></a><span class="co">#&gt;   0.1375</span></span>
<span id="cb14-156"><a href="#cb14-156"></a><span class="co">#&gt;   0.2328</span></span>
<span id="cb14-157"><a href="#cb14-157"></a><span class="co">#&gt;   0.0000</span></span>
<span id="cb14-158"><a href="#cb14-158"></a><span class="co">#&gt;   0.0441</span></span>
<span id="cb14-159"><a href="#cb14-159"></a><span class="co">#&gt;   0.2145</span></span>
<span id="cb14-160"><a href="#cb14-160"></a><span class="co">#&gt; ... [the output was truncated (use n=-1 to disable)]</span></span>
<span id="cb14-161"><a href="#cb14-161"></a><span class="co">#&gt; [ CPUFloatType{101,1913,1} ]</span></span></code></pre></div>
</div>
<div id="training-recurrent-neural-network" class="section level3">
<h3>Training Recurrent Neural Network</h3>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a></span>
<span id="cb15-2"><a href="#cb15-2"></a>optim &lt;-<span class="st"> </span><span class="kw">optim_adagrad</span>(simple_rnn_instance<span class="op">$</span>parameters)</span>
<span id="cb15-3"><a href="#cb15-3"></a></span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>) {</span>
<span id="cb15-5"><a href="#cb15-5"></a>  simple_rnn_instance<span class="op">$</span><span class="kw">zero_grad</span>()</span>
<span id="cb15-6"><a href="#cb15-6"></a>  fcast &lt;-<span class="st"> </span><span class="kw">simple_rnn_instance</span>(X_tensor_cat, X_tensor_rest)</span>
<span id="cb15-7"><a href="#cb15-7"></a>  loss &lt;-<span class="st"> </span><span class="kw">nnf_mse_loss</span>(fcast, y_tensor)</span>
<span id="cb15-8"><a href="#cb15-8"></a>  loss<span class="op">$</span><span class="kw">backward</span>()</span>
<span id="cb15-9"><a href="#cb15-9"></a>  <span class="kw">print</span>(loss)</span>
<span id="cb15-10"><a href="#cb15-10"></a>  optim<span class="op">$</span><span class="kw">step</span>()</span>
<span id="cb15-11"><a href="#cb15-11"></a>}</span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-13"><a href="#cb15-13"></a><span class="co">#&gt; 14.2137</span></span>
<span id="cb15-14"><a href="#cb15-14"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-15"><a href="#cb15-15"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-16"><a href="#cb15-16"></a><span class="co">#&gt; 13.8894</span></span>
<span id="cb15-17"><a href="#cb15-17"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-18"><a href="#cb15-18"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-19"><a href="#cb15-19"></a><span class="co">#&gt; 13.6409</span></span>
<span id="cb15-20"><a href="#cb15-20"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-21"><a href="#cb15-21"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-22"><a href="#cb15-22"></a><span class="co">#&gt; 13.4393</span></span>
<span id="cb15-23"><a href="#cb15-23"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-24"><a href="#cb15-24"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-25"><a href="#cb15-25"></a><span class="co">#&gt; 13.2809</span></span>
<span id="cb15-26"><a href="#cb15-26"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-27"><a href="#cb15-27"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-28"><a href="#cb15-28"></a><span class="co">#&gt; 13.1503</span></span>
<span id="cb15-29"><a href="#cb15-29"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-30"><a href="#cb15-30"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-31"><a href="#cb15-31"></a><span class="co">#&gt; 13.0393</span></span>
<span id="cb15-32"><a href="#cb15-32"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-33"><a href="#cb15-33"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-34"><a href="#cb15-34"></a><span class="co">#&gt; 12.9427</span></span>
<span id="cb15-35"><a href="#cb15-35"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-36"><a href="#cb15-36"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-37"><a href="#cb15-37"></a><span class="co">#&gt; 12.8575</span></span>
<span id="cb15-38"><a href="#cb15-38"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-39"><a href="#cb15-39"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-40"><a href="#cb15-40"></a><span class="co">#&gt; 12.7813</span></span>
<span id="cb15-41"><a href="#cb15-41"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-42"><a href="#cb15-42"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-43"><a href="#cb15-43"></a><span class="co">#&gt; 12.7128</span></span>
<span id="cb15-44"><a href="#cb15-44"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-45"><a href="#cb15-45"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-46"><a href="#cb15-46"></a><span class="co">#&gt; 12.6505</span></span>
<span id="cb15-47"><a href="#cb15-47"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-48"><a href="#cb15-48"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-49"><a href="#cb15-49"></a><span class="co">#&gt; 12.5937</span></span>
<span id="cb15-50"><a href="#cb15-50"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-51"><a href="#cb15-51"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-52"><a href="#cb15-52"></a><span class="co">#&gt; 12.5415</span></span>
<span id="cb15-53"><a href="#cb15-53"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-54"><a href="#cb15-54"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-55"><a href="#cb15-55"></a><span class="co">#&gt; 12.4935</span></span>
<span id="cb15-56"><a href="#cb15-56"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-57"><a href="#cb15-57"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-58"><a href="#cb15-58"></a><span class="co">#&gt; 12.4491</span></span>
<span id="cb15-59"><a href="#cb15-59"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-60"><a href="#cb15-60"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-61"><a href="#cb15-61"></a><span class="co">#&gt; 12.4079</span></span>
<span id="cb15-62"><a href="#cb15-62"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-63"><a href="#cb15-63"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-64"><a href="#cb15-64"></a><span class="co">#&gt; 12.3696</span></span>
<span id="cb15-65"><a href="#cb15-65"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-66"><a href="#cb15-66"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-67"><a href="#cb15-67"></a><span class="co">#&gt; 12.3338</span></span>
<span id="cb15-68"><a href="#cb15-68"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-69"><a href="#cb15-69"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-70"><a href="#cb15-70"></a><span class="co">#&gt; 12.3005</span></span>
<span id="cb15-71"><a href="#cb15-71"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-72"><a href="#cb15-72"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-73"><a href="#cb15-73"></a><span class="co">#&gt; 12.2692</span></span>
<span id="cb15-74"><a href="#cb15-74"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-75"><a href="#cb15-75"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-76"><a href="#cb15-76"></a><span class="co">#&gt; 12.2399</span></span>
<span id="cb15-77"><a href="#cb15-77"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-78"><a href="#cb15-78"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-79"><a href="#cb15-79"></a><span class="co">#&gt; 12.2124</span></span>
<span id="cb15-80"><a href="#cb15-80"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-81"><a href="#cb15-81"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-82"><a href="#cb15-82"></a><span class="co">#&gt; 12.1865</span></span>
<span id="cb15-83"><a href="#cb15-83"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-84"><a href="#cb15-84"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-85"><a href="#cb15-85"></a><span class="co">#&gt; 12.1621</span></span>
<span id="cb15-86"><a href="#cb15-86"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-87"><a href="#cb15-87"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-88"><a href="#cb15-88"></a><span class="co">#&gt; 12.1392</span></span>
<span id="cb15-89"><a href="#cb15-89"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-90"><a href="#cb15-90"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-91"><a href="#cb15-91"></a><span class="co">#&gt; 12.1175</span></span>
<span id="cb15-92"><a href="#cb15-92"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-93"><a href="#cb15-93"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-94"><a href="#cb15-94"></a><span class="co">#&gt; 12.0969</span></span>
<span id="cb15-95"><a href="#cb15-95"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-96"><a href="#cb15-96"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-97"><a href="#cb15-97"></a><span class="co">#&gt; 12.0776</span></span>
<span id="cb15-98"><a href="#cb15-98"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-99"><a href="#cb15-99"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-100"><a href="#cb15-100"></a><span class="co">#&gt; 12.0592</span></span>
<span id="cb15-101"><a href="#cb15-101"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-102"><a href="#cb15-102"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-103"><a href="#cb15-103"></a><span class="co">#&gt; 12.0418</span></span>
<span id="cb15-104"><a href="#cb15-104"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-105"><a href="#cb15-105"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-106"><a href="#cb15-106"></a><span class="co">#&gt; 12.0253</span></span>
<span id="cb15-107"><a href="#cb15-107"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-108"><a href="#cb15-108"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-109"><a href="#cb15-109"></a><span class="co">#&gt; 12.0096</span></span>
<span id="cb15-110"><a href="#cb15-110"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-111"><a href="#cb15-111"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-112"><a href="#cb15-112"></a><span class="co">#&gt; 11.9947</span></span>
<span id="cb15-113"><a href="#cb15-113"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-114"><a href="#cb15-114"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-115"><a href="#cb15-115"></a><span class="co">#&gt; 11.9806</span></span>
<span id="cb15-116"><a href="#cb15-116"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-117"><a href="#cb15-117"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-118"><a href="#cb15-118"></a><span class="co">#&gt; 11.9672</span></span>
<span id="cb15-119"><a href="#cb15-119"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-120"><a href="#cb15-120"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-121"><a href="#cb15-121"></a><span class="co">#&gt; 11.9543</span></span>
<span id="cb15-122"><a href="#cb15-122"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-123"><a href="#cb15-123"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-124"><a href="#cb15-124"></a><span class="co">#&gt; 11.9422</span></span>
<span id="cb15-125"><a href="#cb15-125"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-126"><a href="#cb15-126"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-127"><a href="#cb15-127"></a><span class="co">#&gt; 11.9305</span></span>
<span id="cb15-128"><a href="#cb15-128"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-129"><a href="#cb15-129"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-130"><a href="#cb15-130"></a><span class="co">#&gt; 11.9195</span></span>
<span id="cb15-131"><a href="#cb15-131"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-132"><a href="#cb15-132"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-133"><a href="#cb15-133"></a><span class="co">#&gt; 11.9089</span></span>
<span id="cb15-134"><a href="#cb15-134"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-135"><a href="#cb15-135"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-136"><a href="#cb15-136"></a><span class="co">#&gt; 11.8988</span></span>
<span id="cb15-137"><a href="#cb15-137"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-138"><a href="#cb15-138"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-139"><a href="#cb15-139"></a><span class="co">#&gt; 11.8892</span></span>
<span id="cb15-140"><a href="#cb15-140"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-141"><a href="#cb15-141"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-142"><a href="#cb15-142"></a><span class="co">#&gt; 11.88</span></span>
<span id="cb15-143"><a href="#cb15-143"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-144"><a href="#cb15-144"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-145"><a href="#cb15-145"></a><span class="co">#&gt; 11.8712</span></span>
<span id="cb15-146"><a href="#cb15-146"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-147"><a href="#cb15-147"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-148"><a href="#cb15-148"></a><span class="co">#&gt; 11.8628</span></span>
<span id="cb15-149"><a href="#cb15-149"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-150"><a href="#cb15-150"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-151"><a href="#cb15-151"></a><span class="co">#&gt; 11.8548</span></span>
<span id="cb15-152"><a href="#cb15-152"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-153"><a href="#cb15-153"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-154"><a href="#cb15-154"></a><span class="co">#&gt; 11.8471</span></span>
<span id="cb15-155"><a href="#cb15-155"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-156"><a href="#cb15-156"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-157"><a href="#cb15-157"></a><span class="co">#&gt; 11.8397</span></span>
<span id="cb15-158"><a href="#cb15-158"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-159"><a href="#cb15-159"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-160"><a href="#cb15-160"></a><span class="co">#&gt; 11.8327</span></span>
<span id="cb15-161"><a href="#cb15-161"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-162"><a href="#cb15-162"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-163"><a href="#cb15-163"></a><span class="co">#&gt; 11.8259</span></span>
<span id="cb15-164"><a href="#cb15-164"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-165"><a href="#cb15-165"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-166"><a href="#cb15-166"></a><span class="co">#&gt; 11.8194</span></span>
<span id="cb15-167"><a href="#cb15-167"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-168"><a href="#cb15-168"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-169"><a href="#cb15-169"></a><span class="co">#&gt; 11.8132</span></span>
<span id="cb15-170"><a href="#cb15-170"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-171"><a href="#cb15-171"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-172"><a href="#cb15-172"></a><span class="co">#&gt; 11.8072</span></span>
<span id="cb15-173"><a href="#cb15-173"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-174"><a href="#cb15-174"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-175"><a href="#cb15-175"></a><span class="co">#&gt; 11.8015</span></span>
<span id="cb15-176"><a href="#cb15-176"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-177"><a href="#cb15-177"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-178"><a href="#cb15-178"></a><span class="co">#&gt; 11.796</span></span>
<span id="cb15-179"><a href="#cb15-179"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-180"><a href="#cb15-180"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-181"><a href="#cb15-181"></a><span class="co">#&gt; 11.7907</span></span>
<span id="cb15-182"><a href="#cb15-182"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-183"><a href="#cb15-183"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-184"><a href="#cb15-184"></a><span class="co">#&gt; 11.7856</span></span>
<span id="cb15-185"><a href="#cb15-185"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-186"><a href="#cb15-186"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-187"><a href="#cb15-187"></a><span class="co">#&gt; 11.7807</span></span>
<span id="cb15-188"><a href="#cb15-188"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-189"><a href="#cb15-189"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-190"><a href="#cb15-190"></a><span class="co">#&gt; 11.776</span></span>
<span id="cb15-191"><a href="#cb15-191"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-192"><a href="#cb15-192"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-193"><a href="#cb15-193"></a><span class="co">#&gt; 11.7715</span></span>
<span id="cb15-194"><a href="#cb15-194"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-195"><a href="#cb15-195"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-196"><a href="#cb15-196"></a><span class="co">#&gt; 11.7671</span></span>
<span id="cb15-197"><a href="#cb15-197"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-198"><a href="#cb15-198"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-199"><a href="#cb15-199"></a><span class="co">#&gt; 11.7629</span></span>
<span id="cb15-200"><a href="#cb15-200"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-201"><a href="#cb15-201"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-202"><a href="#cb15-202"></a><span class="co">#&gt; 11.7588</span></span>
<span id="cb15-203"><a href="#cb15-203"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-204"><a href="#cb15-204"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-205"><a href="#cb15-205"></a><span class="co">#&gt; 11.7549</span></span>
<span id="cb15-206"><a href="#cb15-206"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-207"><a href="#cb15-207"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-208"><a href="#cb15-208"></a><span class="co">#&gt; 11.7511</span></span>
<span id="cb15-209"><a href="#cb15-209"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-210"><a href="#cb15-210"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-211"><a href="#cb15-211"></a><span class="co">#&gt; 11.7475</span></span>
<span id="cb15-212"><a href="#cb15-212"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-213"><a href="#cb15-213"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-214"><a href="#cb15-214"></a><span class="co">#&gt; 11.744</span></span>
<span id="cb15-215"><a href="#cb15-215"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-216"><a href="#cb15-216"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-217"><a href="#cb15-217"></a><span class="co">#&gt; 11.7406</span></span>
<span id="cb15-218"><a href="#cb15-218"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-219"><a href="#cb15-219"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-220"><a href="#cb15-220"></a><span class="co">#&gt; 11.7373</span></span>
<span id="cb15-221"><a href="#cb15-221"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-222"><a href="#cb15-222"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-223"><a href="#cb15-223"></a><span class="co">#&gt; 11.7341</span></span>
<span id="cb15-224"><a href="#cb15-224"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-225"><a href="#cb15-225"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-226"><a href="#cb15-226"></a><span class="co">#&gt; 11.731</span></span>
<span id="cb15-227"><a href="#cb15-227"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-228"><a href="#cb15-228"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-229"><a href="#cb15-229"></a><span class="co">#&gt; 11.7281</span></span>
<span id="cb15-230"><a href="#cb15-230"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-231"><a href="#cb15-231"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-232"><a href="#cb15-232"></a><span class="co">#&gt; 11.7252</span></span>
<span id="cb15-233"><a href="#cb15-233"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-234"><a href="#cb15-234"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-235"><a href="#cb15-235"></a><span class="co">#&gt; 11.7224</span></span>
<span id="cb15-236"><a href="#cb15-236"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-237"><a href="#cb15-237"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-238"><a href="#cb15-238"></a><span class="co">#&gt; 11.7197</span></span>
<span id="cb15-239"><a href="#cb15-239"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-240"><a href="#cb15-240"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-241"><a href="#cb15-241"></a><span class="co">#&gt; 11.717</span></span>
<span id="cb15-242"><a href="#cb15-242"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-243"><a href="#cb15-243"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-244"><a href="#cb15-244"></a><span class="co">#&gt; 11.7145</span></span>
<span id="cb15-245"><a href="#cb15-245"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-246"><a href="#cb15-246"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-247"><a href="#cb15-247"></a><span class="co">#&gt; 11.712</span></span>
<span id="cb15-248"><a href="#cb15-248"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-249"><a href="#cb15-249"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-250"><a href="#cb15-250"></a><span class="co">#&gt; 11.7096</span></span>
<span id="cb15-251"><a href="#cb15-251"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-252"><a href="#cb15-252"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-253"><a href="#cb15-253"></a><span class="co">#&gt; 11.7073</span></span>
<span id="cb15-254"><a href="#cb15-254"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-255"><a href="#cb15-255"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-256"><a href="#cb15-256"></a><span class="co">#&gt; 11.705</span></span>
<span id="cb15-257"><a href="#cb15-257"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-258"><a href="#cb15-258"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-259"><a href="#cb15-259"></a><span class="co">#&gt; 11.7028</span></span>
<span id="cb15-260"><a href="#cb15-260"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-261"><a href="#cb15-261"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-262"><a href="#cb15-262"></a><span class="co">#&gt; 11.7007</span></span>
<span id="cb15-263"><a href="#cb15-263"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-264"><a href="#cb15-264"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-265"><a href="#cb15-265"></a><span class="co">#&gt; 11.6986</span></span>
<span id="cb15-266"><a href="#cb15-266"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-267"><a href="#cb15-267"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-268"><a href="#cb15-268"></a><span class="co">#&gt; 11.6965</span></span>
<span id="cb15-269"><a href="#cb15-269"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-270"><a href="#cb15-270"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-271"><a href="#cb15-271"></a><span class="co">#&gt; 11.6945</span></span>
<span id="cb15-272"><a href="#cb15-272"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-273"><a href="#cb15-273"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-274"><a href="#cb15-274"></a><span class="co">#&gt; 11.6926</span></span>
<span id="cb15-275"><a href="#cb15-275"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-276"><a href="#cb15-276"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-277"><a href="#cb15-277"></a><span class="co">#&gt; 11.6907</span></span>
<span id="cb15-278"><a href="#cb15-278"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-279"><a href="#cb15-279"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-280"><a href="#cb15-280"></a><span class="co">#&gt; 11.6889</span></span>
<span id="cb15-281"><a href="#cb15-281"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-282"><a href="#cb15-282"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-283"><a href="#cb15-283"></a><span class="co">#&gt; 11.6871</span></span>
<span id="cb15-284"><a href="#cb15-284"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-285"><a href="#cb15-285"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-286"><a href="#cb15-286"></a><span class="co">#&gt; 11.6853</span></span>
<span id="cb15-287"><a href="#cb15-287"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-288"><a href="#cb15-288"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-289"><a href="#cb15-289"></a><span class="co">#&gt; 11.6836</span></span>
<span id="cb15-290"><a href="#cb15-290"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-291"><a href="#cb15-291"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-292"><a href="#cb15-292"></a><span class="co">#&gt; 11.6819</span></span>
<span id="cb15-293"><a href="#cb15-293"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-294"><a href="#cb15-294"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-295"><a href="#cb15-295"></a><span class="co">#&gt; 11.6803</span></span>
<span id="cb15-296"><a href="#cb15-296"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-297"><a href="#cb15-297"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-298"><a href="#cb15-298"></a><span class="co">#&gt; 11.6787</span></span>
<span id="cb15-299"><a href="#cb15-299"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-300"><a href="#cb15-300"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-301"><a href="#cb15-301"></a><span class="co">#&gt; 11.6771</span></span>
<span id="cb15-302"><a href="#cb15-302"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-303"><a href="#cb15-303"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-304"><a href="#cb15-304"></a><span class="co">#&gt; 11.6756</span></span>
<span id="cb15-305"><a href="#cb15-305"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-306"><a href="#cb15-306"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-307"><a href="#cb15-307"></a><span class="co">#&gt; 11.6741</span></span>
<span id="cb15-308"><a href="#cb15-308"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span>
<span id="cb15-309"><a href="#cb15-309"></a><span class="co">#&gt; torch_tensor</span></span>
<span id="cb15-310"><a href="#cb15-310"></a><span class="co">#&gt; 11.6726</span></span>
<span id="cb15-311"><a href="#cb15-311"></a><span class="co">#&gt; [ CPUFloatType{} ]</span></span></code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc">
      <h2 data-toc-skip>Contents</h2>
    </nav>
      </div>

</div>



      <footer>
      <div class="copyright">
  <p>Developed by <a href='https://krzjoa.github.io'>Krzysztof Joachimiak</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>

