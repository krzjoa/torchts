% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/module-basic-rnn.R
\name{basic_rnn}
\alias{basic_rnn}
\title{Basic RNN module, which handles tensors for both categorical and numeric features}
\usage{
basic_rnn(
  forward_layer = nn_gru,
  backward_layer = NULL,
  fwd_input_size = NULL,
  fwd_output_size = NULL,
  bwd_input_size = NULL,
  bwd_output_size = NULL,
  output_size = 1,
  final_activation = nn_relu(),
  num_embeddings,
  embedding_dim
)
}
\arguments{
\item{forward_layer}{(nn_module_generator or nn_module) A module with forward recurrent layer. Default: \code{nn_gru}}

\item{backward_layer}{(nn_module) A module with backward recurrent layer. Default: \code{NULL}}

\item{fwd_input_size}{(numeric) Input size for the forward recurrent layer}

\item{fwd_output_size}{(numeric) Forward layer size (in other words: the forward layer output size)}

\item{bwd_input_size}{(numeric) Input size for the backward recurrent layer}

\item{bwd_output_size}{(numeric) Backward layer size (in other words: the forward layer output size)}

\item{output_size}{(numeric) Output size of the whole neural network. Default: 1}

\item{final_activation}{The final activation function}
}
\description{
TODO: get rid off fwd_input_size etc.? Compare with other applications
}
\examples{

}
