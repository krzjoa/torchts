% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/module-model-recurrent.R
\name{model_recurrent}
\alias{model_recurrent}
\title{A recurrent neural network model}
\usage{
model_recurrent(
  forward_layer = nn_gru,
  backward_layer = NULL,
  fwd_numeric_input,
  fwd_input_size = NULL,
  fwd_output_size = NULL,
  bwd_input_size = NULL,
  bwd_output_size = NULL,
  output_size = 1,
  final_activation = nn_relu(),
  num_embeddings,
  embedding_dim
)
}
\arguments{
\item{forward_layer}{(nn_module_generator or nn_module) A module with forward recurrent layer. Default: \code{nn_gru}}

\item{backward_layer}{(nn_module) A module with backward recurrent layer. Default: \code{NULL}}

\item{fwd_input_size}{(numeric) Input size for the forward recurrent layer}

\item{fwd_output_size}{(numeric) Forward layer size (in other words: the forward layer output size)}

\item{bwd_input_size}{(numeric) Input size for the backward recurrent layer}

\item{bwd_output_size}{(numeric) Backward layer size (in other words: the forward layer output size)}

\item{output_size}{(numeric) Output size of the whole neural network. Default: 1}

\item{final_activation}{The final activation function}

\item{num_embeddings}{Dictionary sizes for the particular features}

\item{embedding_dim}{}
}
\description{
TODO: get rid off fwd_input_size etc.? Compare with other applications
}
\examples{

}
